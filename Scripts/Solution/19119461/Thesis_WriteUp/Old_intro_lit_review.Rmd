# Introduction \label{Introduction}

A lot of research exists relating text data to various types of financial market or macroeconomic data. Twitter is often the source of text data and the United States stock market is often the source of financial data. However, presidential speeches have so far been overlooked as a potential source of information pertaining to stock markets. This project begins to fill that gap in the literature.

In specific, this project shows that U.S. Presidential Speeches have predictive power over S&P 500 price fluctuations. In order to prove this, natural language processing (NLP), machine learning (ML) and time series analysis were used. The usage of these 3 methods allowed for the comparison of models based on purely financial data with models based on a combination of financial and language data. The result being that the best models are based on a combination of financial and language data outperformed the best purely financial models by about 1 percentage point in terms of predictive accuracy at a daily resolution.

This paper is divided into 4 main sections: a literature review, a data section, an explanation of the experiment design, and a results section. The literature review begins by defending 2 basic conjectures assumed by the undertaking of this project by citing results of other works and concludes by reviewing machine learning (ML) and natural language processing (NLP) methods that those works have used. The data section explains how the data was gathered, cleaned, manipulated, engineered and organised. The experiment section explains the exact construction of various sets of models that could be compared for best performance and finally, the results section reports these performances.

# Literature review \label{Literature review}
The aim of this project is to determine whether U.S Presidential speeches have predictive power over U.S. stock market movements. A positive result would be powerful and could add to the ability of traders to accurately predict stock market movements. Broadly, machine learning has been selected as the method of modelling and the S&P 500 index has been chosen as representative of the ‘stock market’. 

The undertaking of this project assumes 2 important conjectures. First, that there is a correlation between the linguistic factors^[‘Linguistic factors’ in this sense is intended to mean any and all patterns that can be detected in spoken language including verbiage, lexicon, tone, register, sentence length, word combination etc.] of speech employed by U.S. presidents in their speeches and U.S. stock market movements; and second, that the prominence of speech factors can be quantified by using machine learning algorithms. The following literature review defends the two conjectures, confirms the novelty of the project, and surveys methods of data cleaning and analysis to discover which machine learning methods are most appropriate for this project.

## Conjecture defence \label{Conjecture defence}
The following section references the findings of four peer-reviewed articles in defence of the conjectures made in section 1. More evidence exists but is not necessary to sufficiently defend the conjectures made here. 

### FOMC speeches and U.S. financial market reactions \label{FOMC speeches}
@hayo2008communicating[p. 27] performed a generalized auto-regressive conditional heteroscedastic (GARCH) analysis of the relationship between Federal Open Market Committee (FOMC) speeches and the U.S. financial market. The analysis was quantitative on the market side and qualitative on the speech side. They found that FOMC speeches influence trader behavior, but that this effect is both asymmetrical (negative impacts were larger than positive impacts) and non-uniform across trader type (bond markets were affected far more than financial and forex markets). Further, more formal modes of communication have a larger impact on both returns and conditional variance and more prominent speakers have a greater impact on bond markets. Finally, they found that volatility in 3- and 6-month T-bills was reduced on the day of a speech. 

It was commented that heteroskedasticity left something to be desired when assessing the effects of monetary shocks. Further, it was found that speeches alone were not sufficient to create significant effects for financial markets. It is important that news agencies propagate the news for market repercussions to occur. In a brief, informal interview with a few bond traders it was discovered that they tended to “read monetary policy statements and listen to speeches by Greenspan (Bernanke) themselves. Other types of communications are rather neglected and the traders tend to rely on newswire information” [@hayo2008communicating]. Further, it was noted that news articles fail to take a neutral stance on the contents of speeches implying that the market effect may be distorted by the sentiment of news agencies.

This article shows that the sentiments of communications influence the effect of those communications on markets. Thus, analysing sentiment is an important factor in an accurate appraisal of the relationship between speeches and markets. The finding that speeches need to be propagated by news agencies in order to have significant impacts on financial markets is counter to the hypothesis of this project; however the FOMC is less publicly scrutinized than a U.S. president which may render this finding only mildly significant to this project.

###	Political speeches and stock market outcomes \label{Political speeches}
@maligkris2017political demonstrates that the speeches given by U.S. presidential candidates directly influence the stock market, particularly during the early months of their campaigns. These speeches often contain information about potential presidents’ positions on policy changes and public issues. Thus, they can affect investor sentiment and, in turn, the stock market. The employed methodology was to analyse transcripts of presidential candidates' speeches from the American Presidency Project archives and the U.S. Government Publishing Project from the 2004-2016 period according to the index developed in @baker2016measuring (explained in section \ref{policy uncertainty}). He shows, using regression analysis that there is an average increase in excess market returns of 26 basis points following candidate speeches, however the direction and magnitude of this effect varies between candidates. He goes on to examine whether the difference in effect is due to heterogenous speech content. Finally, it was demonstrated that speeches laden with economic information tend to boost stock returns while also reducing volatility. Speeches with a negative tone have the opposite effect and the long run effect of speeches is dependent on market conditions. 

This paper demonstrates that there is a correlation between presidential candidates’ speeches and stock movements. It is then reasonable to believe that there is also a correlation between presidents' speeches and stock market movements. It also highlights that tone affects the relationship and thus that the sentiment of a speech is important. Further, the the paper provides a perfect resource for gathering U.S presidential speech data - the American Presidency Project.

###	Measuring economic policy uncertainty \label{policy uncertainty}
@baker2016measuring develop an Economic Policy Uncertainty Index based on the frequency of articles containing a trio of terms in 10 leading U.S. newspapers. These terms were: ‘ “economic” or “economy” ; “uncertain” or “uncertainty”; and one or more of “congress”, “deficit”, “Federal Reserve”, ‘legislation”, “regulation”, or “White House” ’ [@baker2016measuring,p.1594]. The terms were selected over a period of 24 months during which more than 15 000 news articles were read by humans in an auditing process. The index proved to be quite accurate, spiking near the expected events, including wars, tight presidential elections, fiscal policy battles and terrorist activity. 

They went on to show that their index had a strong relationship with other economic uncertainty measures and policy uncertainty measures. Further, congruence in uncertainty prediction was found between left- and right- leaning newspapers. 

This article shows that language processing can be used to predict economic events, particularly economic uncertainty and economic policy uncertainty. However, the type of language processing proposed for this project differs significantly. While @baker2016measuring used man hours; this project uses machine learning. 

###	Hope, change and financial markets: can Obama’s words drive the market? \label{Obama}
@sazedj2011hope asked whether the speeches made by former U.S. President Barack Obama affected stock market prices. By regressing the event of a speech during Obama’s first 11 months in office on the daily excess returns of the Dow Jones, the S&P 500 and the NASDAQ they found that the event of a speech had a generally insignificant effect on daily excesses. However, by regressing key terms contained in 43 speeches given during the first 11 months of Obama’s presidency it was found that the content of speeches can significantly affect daily excess returns nearly uniformly across all three indices. Notably, the NASDAQ’s correlation to the content of speeches was weaker – indicating that technology markets may be less susceptible to presidential rhetoric. 

This paper highlights the relationship between the content of a presidential speech and stock market returns. However, this study was correlational rather than predictive in nature and therefore does not offer a conclusion on the hypothesis of this project. 

###	Conjecture defence summary \label{defence summary}
As seen in section \ref{Political speeches} and section \ref{Obama} it is true that there is a correlation between the linguistic factors of speech employed by U.S. presidents in their speeches and U.S. stock market movements. Further, section \ref{FOMC speeches} and section \ref{policy uncertainty} show that sentiment and other linguistic factors of speech can be quantified using machine learning methods. Thus, both conjectures hold and further investigation is warranted. This is not the total of all evidence supporting these conjectures but is sufficient. Other articles reviewed here can be seen for further evidence.

##	Novelty \label{novelty}
Searching ‘sentiment analysis stock market’ on Google Scholar yields mostly articles linking Twitter data and the stock market. Searching ‘presidential speeches affect stock market’ on Google Scholar yields articles on the relationship between presidential speeches and the stock market but none using Machine Learning techniques. @khedr2017predicting describe related work as including relating news or Twitter data to stock market behavior and prices and relating financial news to stock prices, but do not mention presidential speeches. Searching ‘machine learning S&P 500’ on Google Scholar yields an array of articles using machine learning as a technical analysis tool but most of these use other financial indicators and are not NLP based – bar one article analysing the effects of former U.S. president, Donald Trump’s tweets on the S&P 500 and the DJIA. Searching ‘political speech machine learning’ on Google Scholar yields articles that focus on political speeches but have no link to stock markets. Other searches yielded similar results, thus as far as can be told – this research is novel in nature. 

##	Data cleaning methods for NLP \label{data cleaning}
@katre2019nlp, in his analysis of Indian political speeches, uses the Natural Language Toolkit (NLTK) package and string methods to remove punctuation, HTML tags and English stopwords^[‘Stopwords’ are words that commonly occur across all speech and therefore only create noise in the data. Some examples are ‘the’, ‘it’, ‘they’ and ‘and’.], as well as converting speeches to lowercase and tokenizing^[‘Tokenizing’ refers to the splitting of words into tokens that have linguistic importance, for example the words ‘terrorism’, ‘terrorist’ and ‘terror’ may all be tokenized to ‘terror’. Thus, the core concept of the word is captured while also simplifying the dataset.] them. @zubair2015extracting, before correlating the sentiment in Reuters articles with S&P 500 movements, clean their text data by tokenizing it with NLTK. @kinyua2021analysis clean their Twitter data (tweets from then U.S. president, Donald Trump) by deleting all tweets on days when the stock trading was closed, deleting all tweets that only contained standard stopwords and deleting all tweets that only contained URLs. @khedr2017predicting tokenize, standardize by converting to lowercase, remove stopwords from and stem^[‘Stemming’ refers to the removal of suffixes to reduce the complexity of a dataset.] their textual data before processing the abbreviations (replacing abbreviations with the full phrase) and filtering out words that consist of two or less characters. 

##	Machine learning methods \label{ML}
The following section looks first at the literature informing the sentiment analysis space and then at the literature around stock market prediction in order to determine methods that suit the intersection between the two. 

###	Sentiment analysis methods \label{sentAnal}
@ren2018forecasting analyse news articles at the sentence level by assigning a sentiment polarity (using software designed for the Chinese language) to each word followed by a sentiment score for each sentence in a document. Each document is then categorized and a sentiment score between -1 and 1 for all news for each day is generated. @zubair2015extracting use the positive and negative valence categories from the Harvard General Enquirer (HGI) to assign each word in a Reuters news article a positive or negative label. They then sum the positives and negatives into a tuple and divide that tuple by the number of words in an article in order to create a vector that represents each news article. The vectors are organized into time series, normalized by dividing all vectors by the first vector, parsed through a Kalman filter and then correlated to S&P 500 returns using Pearson correlation (for both the positive and negative scalar in the vector). @kinyua2021analysis use the Valence Aware Dictionary for Sentiment Reasoning (VADER) to create a sentiment feature for former U.S. president Donald Trump’s tweets which was then used as a regression feature in linear, decision tree and random forest regressions. @khedr2017predicting use N-gram (n=2) to extract key phrases from their corpus of news text data, then term-frequency inverse-document-frequency (TF-IDF) is used to determine the importance of those phrases within the corpus, and finally use a naïve-Bayes classifier to assign positive and negative labels to each news document. @purevdagva2020machine use a variety of features present in both data and metadata to predict fake political speech. Two features relevant to this project were ‘speaker job’ and ‘context’ (press, direct or social) which were labelled using universal serial encoders. For the actual sentiment analysis they used the linguistic inquiry and word count (LIWC) tool to categorize and count words into emotional, cognitive and structural text components. Various further attempts to extract sentiment from the text did not yield increased prediction accuracies. They go on to use an extra tree classifier for feature selection and then support vector machine (SVM), multilayer perceptron, convolutional neural network (CNN), decision trees, fasttext and bidirectional encoder representations from transformers (BERT) for prediction with the highest accuracy resulting from the SVM. @dilaisentiment  use SentiStrength – an automatic sentiment analysis tool - to compare the sentiment in speeches between former U.S. president Donald Trump and former Ukrainian president Petro Poroshenko.

###	Stock market prediction methods \label{stockPred}

@ren2018forecasting use an SVM and five-fold cross validation approach to achieve a prediction accuracy of 98% when predicting fake news in political speech. They combined sentiment data and market indicators as their input data. @kinyua2021analysis use linear, decision tree and random forest regressions to predict S&P 500 and DJIA directional changes. Random forest regression performed best for both datasets. @khedr2017predicting use open, high, low and close (OHLC) prices and the first lag  of directional change as features for prediction of future market trends. @jiao2017predicting extracted lag and window features from the S&P 500 and the global 8 index before running time series random forest, neural network and gradient boosted trees to predict movements of individual stocks in the S&P 500. @liu2016forecasting used forward search feature selection to select features for SVM, naïve-Bayes, Gaussian discriminant analysis and logistic regression from a set of economic features including the crude oil daily return, currency exchange rates and major stock indices daily returns in order to forecast the S&P 500 movement. 

##	Summary of literature review \label{litSumm}
Table \ref{Table 1} represents the literature review in a condensed format which allows for easy comparison of the data and methods used and resulting accuracies. Table \ref{Table 2} represents the metadata, linked through ‘Paper number’ for Table \ref{Table 1}.